{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "basedir = '../../data/eurobarometer/'\n",
    "in_dir = basedir + \"raw_data/\"\n",
    "step1_dir = basedir + \"step1/\"\n",
    "os.makedirs(step1_dir, exist_ok=True)\n",
    "\n",
    "def open_survey(survey):\n",
    "    path = f'{in_dir}{survey}.sav'\n",
    "    df = pd.read_spss(path)\n",
    "    return df\n",
    "\n",
    "def rename(df, frm, to, ls, key, prefix='v'):\n",
    "    keys = [f'{prefix}{i}' for i in range(frm, to + 1)]\n",
    "    df_l = df[keys].apply(lambda x: x.str.lower())\\\n",
    "        .replace('mentioned', 1)\\\n",
    "        .replace({'not mentioned': 0, 'no second language': 0, 'no third language': 0})\\\n",
    "        .fillna(0).astype(int)\n",
    "    new_keys = [f'{key}_{l}' for l in ls]\n",
    "    df_l = df_l.rename(dict(zip(keys, new_keys)), axis=1)\n",
    "    return df_l\n",
    "\n",
    "def piv(df, nq, prefix=\"L2\", prefix2=\"v\"):\n",
    "    key = f'{prefix2}{nq}'\n",
    "    df[key] = df[key].str.capitalize()\n",
    "    d = prefix + '_' + df[key].astype(str).to_frame().replace({'None': 'DK'}).fillna('DK')\n",
    "    d['cnt'] = 1\n",
    "    d = d.pivot(columns=key).fillna(0).astype(int)\n",
    "    d.columns = d.columns.droplevel()\n",
    "    return d\n",
    "\n",
    "def concat_and_save(nat, L1, L2, survey):\n",
    "    res = pd.concat([nat, L1, L2], axis=1)\n",
    "    res = res.drop('L2_nan', axis=1, errors='ignore')\n",
    "    res['Year'] = year\n",
    "    res.to_csv(f'{step1_dir}{survey}.csv', index=False)\n",
    "    return res\n",
    "\n",
    "def get_langs(filename):\n",
    "    with open(f'{in_dir}{filename}') as fp:\n",
    "        return fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Clean up dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB771_2012_ZA5597_v3-0-0'\n",
    "year = 2012\n",
    "df = open_survey(survey)\n",
    "ls = list(map(lambda x: x.title(), get_langs('languages_771.txt')))\n",
    "L1 = rename(df, 1, 39, ls, \"L1\", prefix='d48a_')\n",
    "L2 = pd.DataFrame(index=L1.index, columns=[f\"L2_{l}\" for l in ls]).fillna(0)\n",
    "for nq in ['b', 'c', 'd']:\n",
    "    d = piv(df, nq, prefix2='d48')\n",
    "    L2 = L2 + d\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB634_2005_ZA4411_v1-1-0'\n",
    "year = 2005\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_634.txt')\n",
    "\n",
    "L1 = rename(df, 442, 476, ls, \"L1\")\n",
    "L2 = rename(df, 480, 514, ls, \"L2\")\n",
    "for nq in range(477, 480):\n",
    "    d = piv(df, nq)\n",
    "    L2 = L2 + d\n",
    "    \n",
    "nat = df['v7'].rename('isocntry', axis=1)\n",
    "res = concat_and_save(nat, L1, L2, survey)\n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB643_2005_ZA4415_v1-0-1'\n",
    "year = 2005\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_643.txt')\n",
    "\n",
    "L1 = rename(df, 264, 303, ls, \"L1\")\n",
    "L2 = pd.DataFrame(index=L1.index, columns=[f\"L2_{l}\" for l in ls]).fillna(0)\n",
    "for nq in range(304, 307):\n",
    "    d = piv(df, nq)\n",
    "    L2 = L2 + d\n",
    "\n",
    "nat = df['v7'].rename('isocntry', axis=1)\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB551_2001_ZA3507_v1-0-1'\n",
    "year = 2001\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_551.txt')\n",
    "\n",
    "L2 = rename(df, 39, 53, ls, 'L2')\n",
    "L1 = piv(df, 38, \"L1\")\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB520_1999_ZA3204_v1-0-1'\n",
    "year = 1999\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_520.txt')\n",
    "\n",
    "L2 = rename(df, 49, 63, ls, 'L2')\n",
    "L1 = piv(df, 38, \"L1\")\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB440_1995_ZA2689_v1-0-1'\n",
    "year = 1995\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_440.txt')\n",
    "\n",
    "L1 = rename(df, 264, 280, ls, 'L1')\n",
    "L2 = rename(df, 281, 297, ls, 'L2')\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB340_1990_ZA1960_v1-0-1'\n",
    "year = 1990\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_340.txt')\n",
    "\n",
    "L1 = rename(df, 206, 217, ls, 'L1')\n",
    "L2 = rename(df, 194, 205, ls, 'L2')\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB28_1987_ZA1713_v1-1-0'\n",
    "year = 1987\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_28.txt')\n",
    "\n",
    "L1 = rename(df, 97, 106, ls, 'L1')\n",
    "L2 = rename(df, 87, 96, ls, 'L2')\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 'EB500_1998_ZA3085_v1-1-0'\n",
    "year = 1998\n",
    "df = open_survey(survey)\n",
    "ls = get_langs('languages_500.txt')\n",
    "\n",
    "L2 = rename(df, 39, 55, ls, 'L2')\n",
    "L1 = piv(df, 38, 'L1')\n",
    "\n",
    "nat = df['isocntry']\n",
    "res = concat_and_save(nat, L1, L2, survey)  \n",
    "res.groupby('isocntry').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df, col1, col2):\n",
    "    df[col1] = df[col1] + df[col2]\n",
    "    df = df.drop(col2, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "step2_dir = basedir + \"step2/\"\n",
    "os.makedirs(step2_dir, exist_ok=True)\n",
    "\n",
    "dfs = []\n",
    "for filepath in glob.glob(step1_dir + \"*\"):\n",
    "    dfs.append(pd.read_csv(filepath))\n",
    "    \n",
    "eval_df = pd.concat(dfs, ignore_index=True)\n",
    "eval_df = eval_df.loc[:, eval_df.sum() != 0]\n",
    "\n",
    "repll = [('L2_DK', 'L2_DK '), ('L2_DK', 'L2_None'), ('L1_DK', 'L1_nan'), ('L1_Other', 'L1_Other (specify)'), \n",
    "        ('L1_Portuguese', 'L1_Portug'), ('L2_Portuguese', 'L2_Portug'), ('L1_Luxembourgish', 'L1_Luxembrgsh')]\n",
    "for common, other in repll:\n",
    "    eval_df = combine(eval_df, common, other)\n",
    "\n",
    "eval_df = eval_df.rename({'isocntry': 'ISO_Country'}, axis=1)\n",
    "\n",
    "eval_df.to_csv(step2_dir + 'eval_df_wide.csv')\n",
    "eval_df.groupby(['Year', 'ISO_Country']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "eval_df.columns = list(map(lambda x: re.sub(r'(L.*)(_)(.*)', r'\\3\\2\\1', x), eval_df.columns))\n",
    "ls = set([n.split('_')[0] for n in eval_df.columns if n.endswith('_L1') or n.endswith('_L2')])\n",
    "long = eval_df.reset_index().rename({'index': 'id'}, axis=1)\n",
    "long = pd.wide_to_long(long, stubnames=ls, i='id',j='Proficiency', sep='_', suffix='.*').fillna(0)\n",
    "long.to_csv(step2_dir +'eval_df_long.csv')\n",
    "long.groupby(['Year', 'ISO_Country', 'Proficiency']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}